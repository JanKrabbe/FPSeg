# Dataset Configuration
data_root: /root/datasets/cityscapes # Root directory for the dataset
image_embedding_dir: image_embeddings_mobilesam # Image embedding folder inside data_root. Make sure to use the right embeddings for the encoder that should be used!

p_neg_max: 0.2 # Maximum probability for sampling negative images (with empty mask)
target_size: [1024, 1024] # Image and mask (target) size during training
test_n_class_examples_per_epoch: 500 # Number of images per class in testing to reduce variance since testing is only one epoch

# Model Configuration
encoder: default # SAM encoder to use: default, vit_h, vit_l, vit_b, mobilesam 
# checkpoint: output/distill/2025-01-31_07-32-10/checkpoint.pth # Path to pretrained weights. Make sure to use the right weights for the encoder
checkpoint: weights/sam_vit_h_4b8939.pth # Path to pretrained weights. Make sure to use the right weights for the encoder
tuned_part: prompts # Model parts to train: "prompts" or "prompts and decoder"
n_classes: 33 # Number of classes. 33 classes in CityscapesClasswise dataset (Cityscapes Classes and Categories)
prompt_size: 64 # Size of the prompt (embedding) for each class

# Training Parameters
batch_size: 64 # Number of samples per batch
prompt_learning_rate: 0.01 # Learning rate for prompt tuning
decoder_learning_rate: 0.0001 # Learning rate for decoder (if trained)
n_epochs: 750 # Number of training epochs


# Runtime Configuration
num_workers: 16 # Number of CPU workers for data loading (reduce if necessary)
log_dir: ./output/train # Directory for saving logs
train_log_interval: 50 # Logging interval during training (in batches/optimization steps)
test_interval: 20 # Interval for testing/validation (in epochs)
save_checkpoint: True # Save the best model checkpoint, can be huge with SAM image encoder










